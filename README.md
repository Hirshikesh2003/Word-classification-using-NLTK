# Word-classification-using-NLTK

Before jumping into this project, there's a pre-requisite, please do refer to the repo - "URL - website scraping", where I have covered how to scrape content out a webite.

Coming back to this repo, I have used packages such as NLTK, word tokenizer, WordNetLemmatzer, this project covers the part, where you can classify and conclude the website is in a whole positive or negative, as we are going to find the total number of positive and negative number of words present in the website.

Please download the set of negative and positive words list, and use it in the code, comparing the text document that has the content of the website to the positive and negative words file, is how we can know the number of positve and negative words present.

As we have the total number of positive and negative words, we then can find the polarity of it, along with the total number of words present in the text document can be found, which later help us with finding the average sentence length.

Average number of words per sentence can be found, along with the word count.

This is the basics of classification, as we can build up many more analysis on this website, as we have the total content of it.
